{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining 2016 - Know your Toolbelt\n",
    "\n",
    "In the previous class we have looked at running experiments in batch, both to prove singificant improvement (Experimenter), as well as automatically finding optimal parameter settings (GridSearch). What followed was that both have pro's and cons in comparison to the standard Explorer. In this class, we are going to examine our options a bit more in terms of classifiers and feature selection.\n",
    "\n",
    "## 0.1 - Prepare your Data\n",
    "\n",
    "For this practical, you can work on any set we have used before. The goal will again be to maximize performance on these tasks and see which classifiers will perform best.\n",
    "\n",
    "## 0.2 - Refresher on WEKA\n",
    "\n",
    "What we've seen until now is that WEKA comes with different windows, filters, classifiers, and settings to work with data. Although up until now we've covered basic things, these should be generalizable to *any other* software that you might use in the future. \n",
    "\n",
    "We showed you that in the Experimenter it is possible to perform a multitude of tests under different random conditions (order of the data for example) and test if improvements are significant between classifier A and B, C, and D (using a Paired $t$-test). While this is not common (as it adds another factor of time to your experiments), if you are ever asked to prove that your results perform significantly better, this is the way to do it. Note that you lose the extensive report that WEKA normally provides you in a window, but you can still output this information to `.csv` for example (under `Setup`, `Results destination`). This view can be used to test different classfiers, as well as different parameter settings.\n",
    "\n",
    "We also looked at automatic parameter tuning and how to set it up in WEKA. Note that by default, WEKA doesn't report on the performance of the individual parameters (also not in Experimenter mode), so you lose this information. This is sometimes an issue, as for example when $k = 3$ and $k = 10$ perform slightly different (e.g. accuracy of 91,3% and 91% respectively), that WEKA will opt for the best setting without considering the complexity of the model.\n",
    "\n",
    "## 1 - Naive Bayes\n",
    "\n",
    "In the lectures you were introduced to three new classifiers: Naive Bayes, Random Forests, and SVMs. While the latter two are very complex, Naive Bayes is actually something you can do by hand fairly easily to get a better intuition of what it's doing. That's exactly what we will do in this part. You are given the following instances:\n",
    "\n",
    "|    | sound | action| label |\n",
    "| -- | ----- | ----- | ----- |\n",
    "| 1  | bark  | run   | dog   |\n",
    "| 2  | meow  | run   | cat   |\n",
    "| 3  | meow  | jump  | cat   |\n",
    "| 4  | bark  | run   | dog   |\n",
    "| 5  | bark  | jump  | dog   |\n",
    "| 6  | meow  | run   | cat   |\n",
    "| 7  | bark  | run   | dog   |\n",
    "| 8  | meow  | jump  | cat   |\n",
    "| 9  | bark  | run   | dog   |\n",
    "| 10 | bark  | run   | dog   |\n",
    "| 11 | bark  | jump  | cat   |\n",
    "| 12 | meow  | run   | cat   |\n",
    "\n",
    "\n",
    "Remember that Bayes theorem states the following:\n",
    "\n",
    "### $P(c \\mid x) = \\frac{P( x \\mid c ) P(c)}{P(x)}$\n",
    "\n",
    "Where $c$ is a class (e.g. $\\text{dog}$), and $x$ is a feature value (e.g $\\text{jump}$), so for example $P(\\text{dog} \\mid \\text{jump})$ = $(P(\\text{jump} \\mid \\text{dog}) \\cdot P(\\text{dog})) / P(\\text{jump})$. This would be all occurences of a jumping dog, divided by the total amount of jumps. So $P(\\text{dog} \\mid \\text{jump}) = 1 / 4 = 0.25$. Or, if you run the whole formula: $(1 / 6 \\cdot 6 / 12) / (4 / 12) = 0.25$.\n",
    "\n",
    "For Naive Bayes, however, we assume that all inputs are independent. As such, we only calculate $P(x \\mid c)$, (e.g. $P(\\text{jump} \\mid \\text{dog}$, which is $1 / 6$)). In the training phase, it calculates all possible probabilites given the training data, so it can quickly look them up while applying the formula in the prediction phase.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Do the same for all possible combinations in our training data: \n",
    "    - $P(\\text{jump} \\mid \\text{dog})$\n",
    "    - $P(\\text{jump} \\mid \\text{cat})$\n",
    "    - $P(\\text{run} \\mid \\text{dog})$\n",
    "    - $P(\\text{run} \\mid \\text{cat})$\n",
    "    - $P(\\text{bark} \\mid \\text{dog})$\n",
    "    - $P(\\text{bark} \\mid \\text{cat})$\n",
    "    - $P(\\text{meow} \\mid \\text{dog})$\n",
    "    - $P(\\text{meow} \\mid \\text{cat})$\n",
    "    - $P(\\text{cat})$\n",
    "    - $P(\\text{dog})$\n",
    "2. You've now trained Naive Bayes, do the probabilities already provide you some information?\n",
    "\n",
    "We are given a new instance, of which we don't know the label. We want to predict if it's a cat or a dog using Naive Bayes:\n",
    "\n",
    "|    | sound | action| label |\n",
    "| -- | ----- | ----- | ----- |\n",
    "| 13 | bark  | jump  | ?     |\n",
    "\n",
    "The probability of a certain class (or label) ($c$) given an instance ($X$) is the following (given the simplified naive assumption):\n",
    "\n",
    "### $P(c \\mid X) = P(x_1 \\mid c) \\cdot P(x_2 \\mid c) \\cdot \\ldots \\cdot P(x_n \\mid c) \\cdot P(c)$\n",
    "\n",
    "### Tasks\n",
    "\n",
    "3. Calculate the probability per class using the feature values:\n",
    "    - $P(\\text{cat} \\mid X) = P(\\text{bark} \\mid \\text{cat}) \\cdot P(\\text{jump} \\mid \\text{cat}) \\cdot P(\\text{cat})$\n",
    "    - $P(\\text{dog} \\mid X) = P(\\text{bark} \\mid \\text{dog}) \\cdot P(\\text{jump} \\mid \\text{dog}) \\cdot P(\\text{dog})$\n",
    "4. What class is our instance?\n",
    "\n",
    "## 2 - Naive Bayes, Random Forests and SVMs\n",
    "\n",
    "Apply the three different classifiers to the problems you have done before, under the same settings as you've ran $k$-nn and decision trees.\n",
    "\n",
    "- Naive Bayes: `bayes -> NaiveBayes`\n",
    "- Random Forest: `trees -> Random Forest`\n",
    "- SVM: `functions -> SMO`\n",
    "\n",
    "## 3 - PCA and Feature Selection\n",
    "\n",
    "PCA and any other ways of feature selection can be applied to your data as a filter. However, the easiest, non-permanent way of doing feature selection is to use a meta-classifier.\n",
    "\n",
    "- Under `Classify` click `Choose`.\n",
    "- Navigate to `meta -> AttributeSelectedClassifier`.\n",
    "- Click the name next to `Choose` to select a classifier to run.\n",
    "- You can select `PrincipalComponents` as an evaluator to run PCA.\n",
    "- Within `PrincipalComponents` you can also change the variance it covers (less `==` less features).\n",
    "- Note that if you click `ok` and `Start`, it will warn you that you need to change `search` to `Ranker`.\n",
    "- Go back into the menu, and change `BestFirst` to `Ranker`.\n",
    "- Run your classifier.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Can you interpret from the output if PCA reduced the amount of features?\n",
    "2. Does PCA improve the performance of your classifier?\n",
    "3. What do you think will happen if you start tweaking the covered variance to maximize performance?\n",
    "4. Try to apply PCA to a dataset where you have a training set (IMDB for example). How does optimizing affect your performance on both CV an test?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
